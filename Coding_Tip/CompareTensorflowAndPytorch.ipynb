{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow vs Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow: 2.0.0, torch: 0.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "msg = \"tensorflow: {}, torch: {}\"\n",
    "print(msg.format(tf.__version__, torch.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there is no way to do this in pytorch. However, PyTorch doesn’t pre-occupy the GPU’s entire memory, so if your computation only uses 50% of GPU, only that much is locked by PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpus = tf.config.experimental.list_physical_devices('CPU')\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit option: [VirtualDeviceConfiguration(memory_limit=512)]\n"
     ]
    }
   ],
   "source": [
    "# # GPU 메모리 제한하기\n",
    "MEMORY_LIMIT_CONFIG = [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=512)]\n",
    "tf.config.experimental.set_virtual_device_configuration(gpus[0], MEMORY_LIMIT_CONFIG)\n",
    "msg = \"limit option: {}\"\n",
    "print(msg.format(MEMORY_LIMIT_CONFIG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # only use CPU\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = 1000 # voca sizs\n",
    "B, D, T, H = 2, 3, 5, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      "[[359 595 629   0   0]\n",
      " [632 315 194 190   0]]\n",
      "x_len:\n",
      "[3 4]\n",
      "mask:\n",
      "[[ True  True  True False False]\n",
      " [ True  True  True  True False]]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randint(0, 1000, size=(B, T), dtype=int)\n",
    "# x_len = np.random.randint(0, T + 1, size=(B, ), dtype=int) # This will cause Error!!\n",
    "x_len = np.random.randint(1, T + 1, size=(B, ), dtype=int)\n",
    "for i in range(len(x)):\n",
    "    x[i][x_len[i]:] = 0\n",
    "mask = x!=0\n",
    "msg = \"x:\\n{}\\nx_len:\\n{}\\nmask:\\n{}\"\n",
    "print(msg.format(x, x_len, mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encodeing: Embedding, LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if `tf.test.is_gpu_available()` is executed, all gpu memories can be pre-occupied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.layers as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to tensor\n",
    "inp = tf.convert_to_tensor(x, dtype=tf.int32)\n",
    "inp_len  = tf.convert_to_tensor(x_len, dtype=tf.int32)\n",
    "mask = tf.convert_to_tensor(mask, dtype=tf.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=0, shape=(2, 5), dtype=int32, numpy=\n",
       " array([[359, 595, 629,   0,   0],\n",
       "        [632, 315, 194, 190,   0]], dtype=int32)>,\n",
       " <tf.Tensor: id=1, shape=(2,), dtype=int32, numpy=array([3, 4], dtype=int32)>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp, inp_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed = L.Embedding(V, D, mask_zero=True)\n",
    "embed = L.Embedding(V, D)\n",
    "lstm = L.LSTM(units=H, return_sequences=True, return_state=True)\n",
    "blstm = L.Bidirectional(layer=lstm, merge_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=17, shape=(2, 5, 3), dtype=float32, numpy=\n",
       "array([[[ 0.00159524,  0.03665601, -0.01191108],\n",
       "        [ 0.04492947,  0.01227681, -0.00458068],\n",
       "        [ 0.03699413, -0.0307992 , -0.00333709],\n",
       "        [-0.00643746,  0.0498703 , -0.04670119],\n",
       "        [-0.00643746,  0.0498703 , -0.04670119]],\n",
       "\n",
       "       [[-0.03196247, -0.04721764,  0.02672726],\n",
       "        [ 0.04321711, -0.04162552,  0.03441907],\n",
       "        [ 0.0413607 ,  0.03376241,  0.0028444 ],\n",
       "        [-0.04561653, -0.03750287, -0.04467992],\n",
       "        [-0.00643746,  0.0498703 , -0.04670119]]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#if mask_zero==True, mask values can be compute using embedding methods.\n",
    "print(embed.compute_mask(inp)) \n",
    "print(embed(inp)._keras_mask) # another way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In Tensorflow** ...\n",
    "\n",
    "<font color=red> Please Note that :</font> Error can occurs if <mark>all sequence values are zeros in an example.</mark> Cudnn does not precess this when lstm module is used.  \n",
    "The error message can be shown as follows.\n",
    "\n",
    "<font color=red>UnknownError:</font> CUDNN_STATUS_BAD_PARAM\n",
    "in tensorflow/stream_executor/cuda/cuda_dnn.cc(1424): 'cudnnSetRNNDataDescriptor( data_desc.get(), data_type, layout, max_seq_length, batch_size, data_size, seq_lengths_array, (void*)&padding_fill)' [Op:CudnnRNNV3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=294, shape=(2, 5, 2), dtype=float32, numpy=\n",
       " array([[[-0.00712024, -0.00011674],\n",
       "         [-0.01264691, -0.00656443],\n",
       "         [-0.00940342, -0.01202935],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ]],\n",
       " \n",
       "        [[ 0.01308669,  0.00558831],\n",
       "         [ 0.01686362,  0.00162064],\n",
       "         [ 0.00492537, -0.00131158],\n",
       "         [ 0.00957621, -0.00241367],\n",
       "         [ 0.        ,  0.        ]]], dtype=float32)>,\n",
       " <tf.Tensor: id=298, shape=(2, 2), dtype=float32, numpy=\n",
       " array([[-0.00940342, -0.01202935],\n",
       "        [ 0.00957621, -0.00241367]], dtype=float32)>,\n",
       " <tf.Tensor: id=302, shape=(2, 2), dtype=float32, numpy=\n",
       " array([[-0.01855913, -0.02394593],\n",
       "        [ 0.01943874, -0.00485599]], dtype=float32)>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm(embed(inp)) # [h, ht, ct], automatically applied if embed.mask_zero=True.\n",
    "lstm(embed(inp), mask=mask) # manully plug-in mask values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=762, shape=(2, 5, 2), dtype=float32, numpy=\n",
       " array([[[ 0.00740621, -0.00114337],\n",
       "         [ 0.00714395, -0.0095588 ],\n",
       "         [-0.00048524, -0.0167635 ],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ]],\n",
       " \n",
       "        [[-0.01039943,  0.00912978],\n",
       "         [-0.02368858,  0.00449102],\n",
       "         [-0.01789851, -0.00223974],\n",
       "         [-0.01275576, -0.00316449],\n",
       "         [ 0.        ,  0.        ]]], dtype=float32)>,\n",
       " <tf.Tensor: id=903, shape=(2, 5, 2), dtype=float32, numpy=\n",
       " array([[[-2.6652839e-03, -4.0566991e-03],\n",
       "         [ 3.7362654e-04, -3.2365608e-03],\n",
       "         [ 1.9953572e-03,  2.9448469e-05],\n",
       "         [ 0.0000000e+00,  0.0000000e+00],\n",
       "         [ 0.0000000e+00,  0.0000000e+00]],\n",
       " \n",
       "        [[ 4.8977546e-03,  2.0752738e-03],\n",
       "         [ 3.0945316e-03, -1.2807426e-03],\n",
       "         [ 5.9818052e-04,  2.5921396e-03],\n",
       "         [ 2.9544432e-03,  9.7605204e-03],\n",
       "         [ 0.0000000e+00,  0.0000000e+00]]], dtype=float32)>,\n",
       " <tf.Tensor: id=766, shape=(2, 2), dtype=float32, numpy=\n",
       " array([[-0.00048524, -0.0167635 ],\n",
       "        [-0.01275576, -0.00316449]], dtype=float32)>,\n",
       " <tf.Tensor: id=770, shape=(2, 2), dtype=float32, numpy=\n",
       " array([[-0.00095634, -0.03310474],\n",
       "        [-0.02573843, -0.00626021]], dtype=float32)>,\n",
       " <tf.Tensor: id=896, shape=(2, 2), dtype=float32, numpy=\n",
       " array([[-0.00266528, -0.0040567 ],\n",
       "        [ 0.00489775,  0.00207527]], dtype=float32)>,\n",
       " <tf.Tensor: id=900, shape=(2, 2), dtype=float32, numpy=\n",
       " array([[-0.00526954, -0.00818289],\n",
       "        [ 0.0100137 ,  0.00411511]], dtype=float32)>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_states = [tf.random.normal(shape=[B, H])] * 4 # [ht_fw, ht_bw, ct_fw, bt_bw]\n",
    "blstm(embed(inp), mask=mask, initial_state=init_states) \n",
    "blstm(embed(inp), mask=mask) # outputs # [hf, hb, htf, htb, ctf, ctb]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conver to torch.Tensor\n",
    "inp = torch.LongTensor(x)\n",
    "inp_len = torch.LongTensor(x_len)\n",
    "inp = inp.cuda()\n",
    "inp_len = inp_len.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[359, 595, 629,   0,   0],\n",
       "         [632, 315, 194, 190,   0]], device='cuda:0'),\n",
       " tensor([3, 4], device='cuda:0'))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp, inp_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = nn.Embedding(num_embeddings=V, embedding_dim=D, padding_idx=0).cuda()\n",
    "lstm = nn.LSTM(input_size=D, hidden_size=H, num_layers=1, batch_first=True).cuda()\n",
    "blstm = nn.LSTM(input_size=D, hidden_size=H, num_layers=1, batch_first=True, bidirectional=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.6964, -0.9813,  0.0643],\n",
       "         [ 0.6293,  0.6831, -0.2784],\n",
       "         [ 1.6584,  0.6596, -0.1362],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.3431,  1.0262, -0.9524],\n",
       "         [-0.5076, -1.7151, -0.5414],\n",
       "         [ 0.1196, -0.4846,  1.1399],\n",
       "         [ 0.9370, -1.1598, -1.0287],\n",
       "         [ 0.0000,  0.0000,  0.0000]]],\n",
       "       device='cuda:0', grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.0688, -0.2996],\n",
       "          [ 0.0742, -0.2835],\n",
       "          [ 0.1083, -0.2933],\n",
       "          [ 0.0521, -0.2850],\n",
       "          [ 0.0064, -0.2976]],\n",
       " \n",
       "         [[ 0.0409, -0.2272],\n",
       "          [-0.1513, -0.1366],\n",
       "          [-0.0482, -0.2268],\n",
       "          [-0.0260, -0.2581],\n",
       "          [-0.0226, -0.2709]]], device='cuda:0', grad_fn=<CudnnRnnBackward>),\n",
       " (tensor([[[ 0.0064, -0.2976],\n",
       "           [-0.0226, -0.2709]]], device='cuda:0', grad_fn=<CudnnRnnBackward>),\n",
       "  tensor([[[ 0.0090, -0.4694],\n",
       "           [-0.0318, -0.4152]]], device='cuda:0', grad_fn=<CudnnRnnBackward>)))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defaults initial states are all zeros.\n",
    "# h0 = torch.randn(1*1, B, H) # shape: (num_layers * num_directions, batch, hidden_size)\n",
    "# c0 = torch.randn(1*2, B, H)\n",
    "# inp, (h0, c0) can be a input\n",
    "lstm(embed(inp)) # outputs (h, (ht, ct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.4782,  0.0351, -0.1746,  0.1735],\n",
       "          [-0.5423, -0.1576, -0.1632,  0.1544],\n",
       "          [-0.6151, -0.1166, -0.1237,  0.1812],\n",
       "          [-0.5023, -0.3070, -0.0742,  0.0486],\n",
       "          [-0.4957, -0.4150, -0.0708,  0.0136]],\n",
       " \n",
       "         [[ 0.1661,  0.0499, -0.0780, -0.0444],\n",
       "          [ 0.0195, -0.3287, -0.0032,  0.0009],\n",
       "          [ 0.1570, -0.3652, -0.1026,  0.1766],\n",
       "          [ 0.1661, -0.5768, -0.3078,  0.0862],\n",
       "          [-0.0333, -0.5119, -0.2880,  0.0941]]],\n",
       "        device='cuda:0', grad_fn=<CudnnRnnBackward>),\n",
       " (tensor([[[-0.4957, -0.4150],\n",
       "           [-0.0333, -0.5119]],\n",
       "  \n",
       "          [[-0.1746,  0.1735],\n",
       "           [-0.0780, -0.0444]]], device='cuda:0', grad_fn=<CudnnRnnBackward>),\n",
       "  tensor([[[-1.2094, -0.6821],\n",
       "           [-0.0644, -1.0096]],\n",
       "  \n",
       "          [[-0.4359,  0.7697],\n",
       "           [-0.2197, -0.1102]]], device='cuda:0', grad_fn=<CudnnRnnBackward>)))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h0 = torch.randn(1*2, B, H).cuda() # shape: (num_layers * num_directions, batch, hidden_size)\n",
    "c0 = torch.randn(1*2, B, H).cuda()\n",
    "blstm(embed(inp), (h0, c0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pack, unpack techniques can be used easily in pytorch. [korean blog](https://simonjisu.github.io/nlp/2018/07/05/packedsequence.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([4, 3], device='cuda:0'), tensor([1, 0], device='cuda:0'))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_inp_len, indices = torch.sort(inp_len, dim=0, descending=True)\n",
    "sorted_inp_len, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3431,  1.0262, -0.9524],\n",
       "         [-0.5076, -1.7151, -0.5414],\n",
       "         [ 0.1196, -0.4846,  1.1399],\n",
       "         [ 0.9370, -1.1598, -1.0287],\n",
       "         [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 1.6964, -0.9813,  0.0643],\n",
       "         [ 0.6293,  0.6831, -0.2784],\n",
       "         [ 1.6584,  0.6596, -0.1362],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000]]],\n",
       "       device='cuda:0', grad_fn=<TakeBackward>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed(inp)[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if a seqeunce of an example with all zeros vectors causes `Error`.  \n",
    "the message is shown as follows.  \n",
    "<font color=red>ValueError</font>: Length of all samples has to be greater than 0, but found an element in 'lengths' that is <= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[ 0.3431,  1.0262, -0.9524],\n",
       "        [ 1.6964, -0.9813,  0.0643],\n",
       "        [-0.5076, -1.7151, -0.5414],\n",
       "        [ 0.6293,  0.6831, -0.2784],\n",
       "        [ 0.1196, -0.4846,  1.1399],\n",
       "        [ 1.6584,  0.6596, -0.1362],\n",
       "        [ 0.9370, -1.1598, -1.0287]],\n",
       "       device='cuda:0', grad_fn=<PackPaddedBackward>), batch_sizes=tensor([2, 2, 2, 1], grad_fn=<PackPaddedBackward>))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed_embeddings = pack_padded_sequence(embed(inp)[indices], sorted_inp_len.data.tolist(), batch_first=True)\n",
    "packed_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PackedSequence(data=tensor([[-0.3480, -0.1531,  0.0350, -0.0619],\n",
       "         [ 0.2600, -0.2039, -0.1305,  0.1756],\n",
       "         [-0.2834, -0.5071,  0.2104, -0.0072],\n",
       "         [-0.1044, -0.1516, -0.1276,  0.1511],\n",
       "         [-0.1307, -0.5428,  0.0541,  0.1854],\n",
       "         [-0.2404, -0.0354, -0.0786,  0.1734],\n",
       "         [-0.1927, -0.6621, -0.0166,  0.0799]],\n",
       "        device='cuda:0', grad_fn=<CudnnRnnBackward>), batch_sizes=tensor([2, 2, 2, 1], grad_fn=<PackPaddedBackward>)),\n",
       " (tensor([[[-0.1927, -0.6621],\n",
       "           [-0.2404, -0.0354]],\n",
       "  \n",
       "          [[ 0.0350, -0.0619],\n",
       "           [-0.1305,  0.1756]]], device='cuda:0', grad_fn=<CudnnRnnBackward>),\n",
       "  tensor([[[-0.2740, -1.2842],\n",
       "           [-0.2947, -0.0455]],\n",
       "  \n",
       "          [[ 0.0900, -0.1426],\n",
       "           [-0.3127,  0.7660]]], device='cuda:0', grad_fn=<CudnnRnnBackward>)))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed_h, (packed_hn, packed_cn) = blstm(packed_embeddings) # outputs packed results.\n",
    "packed_h, (packed_hn, packed_cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 2])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed_hn.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[632, 315, 194, 190,   0],\n",
       "        [359, 595, 629,   0,   0]], device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.3480, -0.1531,  0.0350, -0.0619],\n",
       "          [-0.2834, -0.5071,  0.2104, -0.0072],\n",
       "          [-0.1307, -0.5428,  0.0541,  0.1854],\n",
       "          [-0.1927, -0.6621, -0.0166,  0.0799]],\n",
       " \n",
       "         [[ 0.2600, -0.2039, -0.1305,  0.1756],\n",
       "          [-0.1044, -0.1516, -0.1276,  0.1511],\n",
       "          [-0.2404, -0.0354, -0.0786,  0.1734],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000]]],\n",
       "        device='cuda:0', grad_fn=<TransposeBackward0>), tensor([4, 3]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_packed_sequence(packed_h, batch_first=True) # unpack the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Finial hidden states of Bi-LSTM:  \n",
    "    * [`last forward vector`, `last backward vector = first vector of output`]: `[B, 2, H]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1927, -0.6621],\n",
       "         [-0.2404, -0.0354]],\n",
       "\n",
       "        [[ 0.0350, -0.0619],\n",
       "         [-0.1305,  0.1756]]], device='cuda:0', grad_fn=<CudnnRnnBackward>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed_hn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big-Difference tensorflow vs pytorch\n",
    "1. **Embedding**  \n",
    "    **In Tensorflow**, even though `mask_zero=True`, the outputs of embedding layer for `padding id=0` does not zero-vector.  \n",
    "    <font color=red>On the other hand</font>, \n",
    "    **In Pytorch**, embedding layer's signiture `padding_idx` can determine outputs to become zero-vector.\n",
    "    \n",
    "2. **LSTM**   \n",
    "    * **In Tensorflow**, if a seqeunce of an example with all zeros vectors causes `Error` in GPU commputing.  \n",
    "      <font color=red>On the other hand</font>, **In Pytorch**, a seqeunce with all zeros vectors does not cause `Error` in GPU commputing.\n",
    "    * Automatical masked outputs in LSTM can be supplied in Tensorflow, but pytorch does not have this.\n",
    "    * Pytorch supplies packed, unpacked technique for efficient computation when treating LSTM sequences.  \n",
    "      <font color=red>However</font>, in this technique, if a seqeunce of an example with all zeros vectors causes `Error`\n",
    "      \n",
    "   <font color=skyblue> Solution</font>: To prevent `Error` related to all zero vectors, all values of input_len should be larger than 0 \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create class `Embedding` in Tensorflow which operates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(tf.keras.layers.Layer):\n",
    "  \n",
    "    def __init__(self, input_dim, output_dim, padding_idx=0, **kwargs):\n",
    "        \"\"\" default padding_idx=0.\n",
    "        \n",
    "        Call Args:\n",
    "            inputs: [B, T]\n",
    "        \n",
    "        description:\n",
    "            input_dim: V (vocabulary size)\n",
    "            output_dim: D \n",
    "        \"\"\"\n",
    "        super(Embedding, self).__init__(**kwargs)\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.padding_idx = padding_idx\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.embeddings = self.add_weight(\n",
    "          shape=(self.input_dim, self.output_dim),\n",
    "          initializer='random_normal',\n",
    "          dtype='float32')\n",
    "\n",
    "    def call(self, inputs): \n",
    "        def compute_mask():\n",
    "            return tf.not_equal(inputs, self.padding_idx)\n",
    "        \n",
    "        out = tf.nn.embedding_lookup(self.embeddings, inputs)\n",
    "        masking = compute_mask() # [B, T], bool\n",
    "        masking = tf.cast(tf.tile(masking[:,:, tf.newaxis], [1,1,self.output_dim]), \n",
    "                          dtype=tf.float32) # [B, T, D]\n",
    "        return tf.multiply(out, masking)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = Embedding(V, D, padding_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### regenerate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      "[[965 176 491 801 149]\n",
      " [538 162 287 297 610]]\n",
      "x_len:\n",
      "[5 5]\n",
      "mask:\n",
      "[[ True  True  True  True  True]\n",
      " [ True  True  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randint(0, 1000, size=(B, T), dtype=int)\n",
    "# x_len = np.random.randint(0, T + 1, size=(B, ), dtype=int) # This will cause Error!!\n",
    "x_len = np.random.randint(1, T + 1, size=(B, ), dtype=int)\n",
    "for i in range(len(x)):\n",
    "    x[i][x_len[i]:] = 0\n",
    "mask = x!=0\n",
    "msg = \"x:\\n{}\\nx_len:\\n{}\\nmask:\\n{}\"\n",
    "print(msg.format(x, x_len, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to tensor\n",
    "inp = tf.convert_to_tensor(x, dtype=tf.int32)\n",
    "inp_len  = tf.convert_to_tensor(x_len, dtype=tf.int32)\n",
    "mask = tf.convert_to_tensor(mask, dtype=tf.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=904, shape=(2, 5), dtype=int32, numpy=\n",
       " array([[965, 176, 491, 801, 149],\n",
       "        [538, 162, 287, 297, 610]], dtype=int32)>,\n",
       " <tf.Tensor: id=906, shape=(2, 5), dtype=bool, numpy=\n",
       " array([[ True,  True,  True,  True,  True],\n",
       "        [ True,  True,  True,  True,  True]])>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_mask = np.array([[True, False, False, False, False],\n",
    "#         [ True,  True,  True, False, False]])\n",
    "# test_mask = tf.convert_to_tensor(test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=930, shape=(2, 5, 3), dtype=float32, numpy=\n",
       "array([[[ 0.0416598 ,  0.0018823 ,  0.06277428],\n",
       "        [ 0.02224987,  0.00704473,  0.02094294],\n",
       "        [-0.02784282, -0.06249573,  0.00104964],\n",
       "        [ 0.09029059,  0.06687873,  0.08003117],\n",
       "        [-0.01774345,  0.0964142 , -0.12424164]],\n",
       "\n",
       "       [[-0.0317932 , -0.08884034,  0.02873092],\n",
       "        [-0.10553911, -0.03988774, -0.0694226 ],\n",
       "        [ 0.0517051 ,  0.01909538,  0.00886771],\n",
       "        [-0.04648464,  0.09031732, -0.01851485],\n",
       "        [ 0.00429158, -0.02031239,  0.02710586]]], dtype=float32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = L.LSTM(units=H, return_sequences=True, return_state=True)\n",
    "blstm = L.Bidirectional(layer=lstm, merge_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=1112, shape=(2, 5, 2), dtype=float32, numpy=\n",
       " array([[[-0.01064905,  0.00394847],\n",
       "         [-0.01063567,  0.00473839],\n",
       "         [-0.01129253, -0.00097121],\n",
       "         [-0.01781004,  0.00965991],\n",
       "         [ 0.01671795,  0.00570279]],\n",
       " \n",
       "        [[-0.01029179, -0.00404594],\n",
       "         [ 0.00095257, -0.00189471],\n",
       "         [ 0.00074197, -0.00608036],\n",
       "         [ 0.00769171,  0.01725223],\n",
       "         [ 0.00087247,  0.01191795]]], dtype=float32)>,\n",
       " <tf.Tensor: id=1116, shape=(2, 2), dtype=float32, numpy=\n",
       " array([[0.01671795, 0.00570279],\n",
       "        [0.00087247, 0.01191795]], dtype=float32)>,\n",
       " <tf.Tensor: id=1120, shape=(2, 2), dtype=float32, numpy=\n",
       " array([[0.03161679, 0.01112464],\n",
       "        [0.00175713, 0.02399201]], dtype=float32)>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm(embed(inp), mask=mask) #  [h, ht, ct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=1356, shape=(2, 5, 2), dtype=float32, numpy=\n",
       " array([[[-0.00511874,  0.00858796],\n",
       "         [-0.00808002,  0.01097147],\n",
       "         [ 0.00567391,  0.00636496],\n",
       "         [-0.01547743,  0.02149273],\n",
       "         [-0.02562061,  0.00905941]],\n",
       " \n",
       "        [[ 0.01695154, -0.00168698],\n",
       "         [ 0.03395947, -0.01169712],\n",
       "         [ 0.01980755, -0.0082969 ],\n",
       "         [ 0.0138903 , -0.00401598],\n",
       "         [ 0.01490065, -0.00126571]]], dtype=float32)>,\n",
       " <tf.Tensor: id=1497, shape=(2, 5, 2), dtype=float32, numpy=\n",
       " array([[[ 0.013806  ,  0.0142377 ],\n",
       "         [ 0.00849442,  0.00643777],\n",
       "         [ 0.00585771,  0.00317722],\n",
       "         [ 0.02268172, -0.0008881 ],\n",
       "         [ 0.00189724, -0.01832626]],\n",
       " \n",
       "        [[-0.02280359, -0.00843212],\n",
       "         [-0.01733721, -0.01760674],\n",
       "         [ 0.00902378, -0.00283928],\n",
       "         [-0.00303076, -0.01425412],\n",
       "         [-0.00029973,  0.00394505]]], dtype=float32)>,\n",
       " <tf.Tensor: id=1360, shape=(2, 2), dtype=float32, numpy=\n",
       " array([[-0.02562061,  0.00905941],\n",
       "        [ 0.01490065, -0.00126571]], dtype=float32)>,\n",
       " <tf.Tensor: id=1364, shape=(2, 2), dtype=float32, numpy=\n",
       " array([[-0.05175059,  0.01903152],\n",
       "        [ 0.02978283, -0.00251175]], dtype=float32)>,\n",
       " <tf.Tensor: id=1490, shape=(2, 2), dtype=float32, numpy=\n",
       " array([[ 0.013806  ,  0.0142377 ],\n",
       "        [-0.02280359, -0.00843212]], dtype=float32)>,\n",
       " <tf.Tensor: id=1494, shape=(2, 2), dtype=float32, numpy=\n",
       " array([[ 0.02729905,  0.02839736],\n",
       "        [-0.04494345, -0.01696696]], dtype=float32)>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blstm(embed(inp), mask=mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ts20",
   "language": "python",
   "name": "ts20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
