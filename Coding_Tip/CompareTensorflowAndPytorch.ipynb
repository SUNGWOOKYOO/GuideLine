{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow vs Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow: 2.0.0, torch: 0.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "msg = \"tensorflow: {}, torch: {}\"\n",
    "print(msg.format(tf.__version__, torch.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there is no way to do this in pytorch. However, PyTorch doesn’t pre-occupy the GPU’s entire memory, so if your computation only uses 50% of GPU, only that much is locked by PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpus = tf.config.experimental.list_physical_devices('CPU')\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "limit option: [VirtualDeviceConfiguration(memory_limit=512)]\n"
     ]
    }
   ],
   "source": [
    "# # GPU 메모리 제한하기\n",
    "MEMORY_LIMIT_CONFIG = [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=512)]\n",
    "tf.config.experimental.set_virtual_device_configuration(gpus[0], MEMORY_LIMIT_CONFIG)\n",
    "msg = \"limit option: {}\"\n",
    "print(msg.format(MEMORY_LIMIT_CONFIG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # only use CPU\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = 1000 # voca sizs\n",
    "B, D, T, H = 2, 3, 5, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      "[[595 856 358 165   0]\n",
      " [705   0   0   0   0]]\n",
      "x_len:\n",
      "[4 1]\n",
      "mask:\n",
      "[[ True  True  True  True False]\n",
      " [ True False False False False]]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randint(0, 1000, size=(B, T), dtype=int)\n",
    "# x_len = np.random.randint(0, T + 1, size=(B, ), dtype=int) # This will cause Error!!\n",
    "x_len = np.random.randint(1, T + 1, size=(B, ), dtype=int)\n",
    "for i in range(len(x)):\n",
    "    x[i][x_len[i]:] = 0\n",
    "mask = x!=0\n",
    "msg = \"x:\\n{}\\nx_len:\\n{}\\nmask:\\n{}\"\n",
    "print(msg.format(x, x_len, mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encodeing: Embedding, LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if `tf.test.is_gpu_available()` is executed, all gpu memories can be pre-occupied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.layers as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to tensor\n",
    "inp = tf.convert_to_tensor(x, dtype=tf.int32)\n",
    "inp_len  = tf.convert_to_tensor(x_len, dtype=tf.int32)\n",
    "mask = tf.convert_to_tensor(mask, dtype=tf.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=0, shape=(2, 5), dtype=int32, numpy=\n",
       " array([[595, 856, 358, 165,   0],\n",
       "        [705,   0,   0,   0,   0]], dtype=int32)>,\n",
       " <tf.Tensor: id=1, shape=(2,), dtype=int32, numpy=array([4, 1], dtype=int32)>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp, inp_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed = L.Embedding(V, D, mask_zero=True)\n",
    "embed = L.Embedding(V, D)\n",
    "lstm = L.LSTM(units=H, return_sequences=True, return_state=True)\n",
    "blstm = L.Bidirectional(layer=lstm, merge_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=17, shape=(2, 5, 3), dtype=float32, numpy=\n",
       "array([[[ 0.01795701, -0.03862273, -0.00558972],\n",
       "        [ 0.01919926, -0.04094749,  0.01460603],\n",
       "        [-0.01255976,  0.02137837, -0.02569915],\n",
       "        [ 0.03439699, -0.00957326,  0.02156724],\n",
       "        [-0.03864299,  0.00503808, -0.02458462]],\n",
       "\n",
       "       [[ 0.00422397, -0.03477051,  0.00359398],\n",
       "        [-0.03864299,  0.00503808, -0.02458462],\n",
       "        [-0.03864299,  0.00503808, -0.02458462],\n",
       "        [-0.03864299,  0.00503808, -0.02458462],\n",
       "        [-0.03864299,  0.00503808, -0.02458462]]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#if mask_zero==True, mask values can be compute using embedding methods.\n",
    "print(embed.compute_mask(inp)) \n",
    "print(embed(inp)._keras_mask) # another way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In Tensorflow** ...\n",
    "\n",
    "<font color=red> Please Note that :</font> Error can occurs if <mark>all sequence values are zeros in an example.</mark> Cudnn does not precess this when lstm module is used.  \n",
    "The error message can be shown as follows.\n",
    "\n",
    "<font color=red>UnknownError:</font> CUDNN_STATUS_BAD_PARAM\n",
    "in tensorflow/stream_executor/cuda/cuda_dnn.cc(1424): 'cudnnSetRNNDataDescriptor( data_desc.get(), data_type, layout, max_seq_length, batch_size, data_size, seq_lengths_array, (void*)&padding_fill)' [Op:CudnnRNNV3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=294, shape=(2, 5, 2), dtype=float32, numpy=\n",
       " array([[[ 0.00317005,  0.00056077],\n",
       "         [ 0.0047301 ,  0.00393966],\n",
       "         [ 0.00361286, -0.00128846],\n",
       "         [-0.00114782, -0.00159627],\n",
       "         [ 0.        ,  0.        ]],\n",
       " \n",
       "        [[ 0.00390952,  0.00336001],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ]]], dtype=float32)>,\n",
       " <tf.Tensor: id=298, shape=(2, 2), dtype=float32, numpy=\n",
       " array([[-0.00114782, -0.00159627],\n",
       "        [ 0.00390952,  0.00336001]], dtype=float32)>,\n",
       " <tf.Tensor: id=302, shape=(2, 2), dtype=float32, numpy=\n",
       " array([[-0.002287  , -0.0031701 ],\n",
       "        [ 0.0077549 ,  0.00679565]], dtype=float32)>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm(embed(inp)) # [h, ht, ct], automatically applied if embed.mask_zero=True.\n",
    "lstm(embed(inp), mask=mask) # manully plug-in mask values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=762, shape=(2, 5, 2), dtype=float32, numpy=\n",
       " array([[[-0.00506626, -0.00420797],\n",
       "         [-0.00882048, -0.0062254 ],\n",
       "         [-0.00710497, -0.00252964],\n",
       "         [-0.00567203, -0.00647691],\n",
       "         [ 0.        ,  0.        ]],\n",
       " \n",
       "        [[-0.0040854 , -0.00124973],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ]]], dtype=float32)>,\n",
       " <tf.Tensor: id=903, shape=(2, 5, 2), dtype=float32, numpy=\n",
       " array([[[-0.00546061, -0.01607447],\n",
       "         [-0.00268578, -0.0077665 ],\n",
       "         [ 0.00279986, -0.00162677],\n",
       "         [-0.00161444, -0.00275692],\n",
       "         [ 0.        ,  0.        ]],\n",
       " \n",
       "        [[-0.00383861, -0.00539634],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ]]], dtype=float32)>,\n",
       " <tf.Tensor: id=766, shape=(2, 2), dtype=float32, numpy=\n",
       " array([[-0.00567203, -0.00647691],\n",
       "        [-0.0040854 , -0.00124973]], dtype=float32)>,\n",
       " <tf.Tensor: id=770, shape=(2, 2), dtype=float32, numpy=\n",
       " array([[-0.01135254, -0.01301852],\n",
       "        [-0.00820199, -0.00251352]], dtype=float32)>,\n",
       " <tf.Tensor: id=896, shape=(2, 2), dtype=float32, numpy=\n",
       " array([[-0.00546061, -0.01607447],\n",
       "        [-0.00383861, -0.00539634]], dtype=float32)>,\n",
       " <tf.Tensor: id=900, shape=(2, 2), dtype=float32, numpy=\n",
       " array([[-0.010927  , -0.03171666],\n",
       "        [-0.00764174, -0.01066241]], dtype=float32)>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_states = [tf.random.normal(shape=[B, H])] * 4 # [ht_fw, ht_bw, ct_fw, bt_bw]\n",
    "blstm(embed(inp), mask=mask, initial_state=init_states) \n",
    "blstm(embed(inp), mask=mask) # outputs # [hf, hb, htf, htb, ctf, ctb]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conver to torch.Tensor\n",
    "inp = torch.LongTensor(x)\n",
    "inp_len = torch.LongTensor(x_len)\n",
    "inp = inp.cuda()\n",
    "inp_len = inp_len.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[595, 856, 358, 165,   0],\n",
       "         [705,   0,   0,   0,   0]], device='cuda:0'),\n",
       " tensor([4, 1], device='cuda:0'))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp, inp_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = nn.Embedding(num_embeddings=V, embedding_dim=D, padding_idx=0).cuda()\n",
    "lstm = nn.LSTM(input_size=D, hidden_size=H, num_layers=1, batch_first=True).cuda()\n",
    "blstm = nn.LSTM(input_size=D, hidden_size=H, num_layers=1, batch_first=True, bidirectional=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0108,  0.0929, -1.6743],\n",
       "         [-0.4543,  0.8441, -0.5434],\n",
       "         [-1.1308,  1.0828, -0.6759],\n",
       "         [ 1.0714,  0.3594,  1.7790],\n",
       "         [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.2507, -1.3260, -0.7707],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000]]],\n",
       "       device='cuda:0', grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.1659,  0.1207],\n",
       "          [-0.1313,  0.1584],\n",
       "          [-0.1283,  0.1270],\n",
       "          [ 0.0030,  0.1742],\n",
       "          [-0.0242,  0.2194]],\n",
       " \n",
       "         [[ 0.1015,  0.2408],\n",
       "          [-0.0062,  0.3109],\n",
       "          [-0.0354,  0.3059],\n",
       "          [-0.0461,  0.3046],\n",
       "          [-0.0500,  0.3044]]], device='cuda:0', grad_fn=<CudnnRnnBackward>),\n",
       " (tensor([[[-0.0242,  0.2194],\n",
       "           [-0.0500,  0.3044]]], device='cuda:0', grad_fn=<CudnnRnnBackward>),\n",
       "  tensor([[[-0.0628,  0.4446],\n",
       "           [-0.1354,  0.6597]]], device='cuda:0', grad_fn=<CudnnRnnBackward>)))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defaults initial states are all zeros.\n",
    "# h0 = torch.randn(1*1, B, H) # shape: (num_layers * num_directions, batch, hidden_size)\n",
    "# c0 = torch.randn(1*2, B, H)\n",
    "# inp, (h0, c0) can be a input\n",
    "lstm(embed(inp)) # outputs (h, (ht, ct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.3166, -0.0375,  0.1704, -0.0853],\n",
       "          [-0.0481,  0.2206,  0.4176, -0.0310],\n",
       "          [ 0.0783,  0.3529,  0.4082, -0.0505],\n",
       "          [ 0.0209, -0.0261,  0.3105, -0.5865],\n",
       "          [-0.0894,  0.0179, -0.1782, -0.0385]],\n",
       " \n",
       "         [[ 0.0031,  0.1702,  0.1792, -0.2081],\n",
       "          [-0.0807,  0.0830,  0.4344, -0.3378],\n",
       "          [-0.1149,  0.0826,  0.4302, -0.3379],\n",
       "          [-0.1261,  0.0914,  0.4153, -0.3432],\n",
       "          [-0.1296,  0.0972,  0.4747, -0.1887]]],\n",
       "        device='cuda:0', grad_fn=<CudnnRnnBackward>),\n",
       " (tensor([[[-0.0894,  0.0179],\n",
       "           [-0.1296,  0.0972]],\n",
       "  \n",
       "          [[ 0.1704, -0.0853],\n",
       "           [ 0.1792, -0.2081]]], device='cuda:0', grad_fn=<CudnnRnnBackward>),\n",
       "  tensor([[[-0.1532,  0.0319],\n",
       "           [-0.2321,  0.1690]],\n",
       "  \n",
       "          [[ 0.3068, -0.3076],\n",
       "           [ 0.4212, -1.1216]]], device='cuda:0', grad_fn=<CudnnRnnBackward>)))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h0 = torch.randn(1*2, B, H).cuda() # shape: (num_layers * num_directions, batch, hidden_size)\n",
    "c0 = torch.randn(1*2, B, H).cuda()\n",
    "blstm(embed(inp), (h0, c0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pack, unpack techniques can be used easily in pytorch. [korean blog](https://simonjisu.github.io/nlp/2018/07/05/packedsequence.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([4, 1], device='cuda:0'), tensor([0, 1], device='cuda:0'))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_inp_len, indices = torch.sort(inp_len, dim=0, descending=True)\n",
    "sorted_inp_len, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0108,  0.0929, -1.6743],\n",
       "         [-0.4543,  0.8441, -0.5434],\n",
       "         [-1.1308,  1.0828, -0.6759],\n",
       "         [ 1.0714,  0.3594,  1.7790],\n",
       "         [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.2507, -1.3260, -0.7707],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000]]],\n",
       "       device='cuda:0', grad_fn=<TakeBackward>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed(inp)[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if a seqeunce of an example with all zeros vectors causes `Error`.  \n",
    "the message is shown as follows.  \n",
    "<font color=red>ValueError</font>: Length of all samples has to be greater than 0, but found an element in 'lengths' that is <= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[-0.0108,  0.0929, -1.6743],\n",
       "        [ 0.2507, -1.3260, -0.7707],\n",
       "        [-0.4543,  0.8441, -0.5434],\n",
       "        [-1.1308,  1.0828, -0.6759],\n",
       "        [ 1.0714,  0.3594,  1.7790]],\n",
       "       device='cuda:0', grad_fn=<PackPaddedBackward>), batch_sizes=tensor([2, 1, 1, 1], grad_fn=<PackPaddedBackward>))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed_embeddings = pack_padded_sequence(embed(inp)[indices], sorted_inp_len.data.tolist(), batch_first=True)\n",
    "packed_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PackedSequence(data=tensor([[-0.1659,  0.1207],\n",
       "         [ 0.1015,  0.2408],\n",
       "         [-0.1313,  0.1584],\n",
       "         [-0.1283,  0.1270],\n",
       "         [ 0.0030,  0.1742]], device='cuda:0', grad_fn=<CudnnRnnBackward>), batch_sizes=tensor([2, 1, 1, 1], grad_fn=<PackPaddedBackward>)),\n",
       " (tensor([[[0.0030, 0.1742],\n",
       "           [0.1015, 0.2408]]], device='cuda:0', grad_fn=<CudnnRnnBackward>),\n",
       "  tensor([[[0.0086, 0.2180],\n",
       "           [0.1640, 0.7270]]], device='cuda:0', grad_fn=<CudnnRnnBackward>)))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed_h, (packed_ht_fw, packed_ht_bw) = lstm(packed_embeddings) # outputs packed results.\n",
    "packed_h, (packed_ht_fw, packed_ht_bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.1659,  0.1207],\n",
       "          [-0.1313,  0.1584],\n",
       "          [-0.1283,  0.1270],\n",
       "          [ 0.0030,  0.1742]],\n",
       " \n",
       "         [[ 0.1015,  0.2408],\n",
       "          [ 0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000]]], device='cuda:0', grad_fn=<TransposeBackward0>),\n",
       " tensor([4, 1]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_packed_sequence(packed_h, batch_first=True) # unpack the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big-Difference tensorflow vs pytorch\n",
    "1. **Embedding**  \n",
    "    **In Tensorflow**, even though `mask_zero=True`, the outputs of embedding layer for `padding id=0` does not zero-vector.  \n",
    "    <font color=red>On the other hand</font>, \n",
    "    **In Pytorch**, embedding layer's signiture `padding_idx` can determine outputs to become zero-vector.\n",
    "    \n",
    "2. **LSTM**   \n",
    "    * **In Tensorflow**, if a seqeunce of an example with all zeros vectors causes `Error` in GPU commputing.  \n",
    "      <font color=red>On the other hand</font>, **In Pytorch**, a seqeunce with all zeros vectors does not cause `Error` in GPU commputing.\n",
    "    * Automatical masked outputs in LSTM can be supplied in Tensorflow, but pytorch does not have this.\n",
    "    * Pytorch supplies packed, unpacked technique for efficient computation when treating LSTM sequences.  \n",
    "      <font color=red>However</font>, in this technique, if a seqeunce of an example with all zeros vectors causes `Error`\n",
    "      \n",
    "   <font color=skyblue> Solution</font>: To prevent `Error` related to all zero vectors, all values of input_len should be larger than 0 \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create class `Embedding` in Tensorflow which operates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(tf.keras.layers.Layer):\n",
    "  \n",
    "    def __init__(self, input_dim, output_dim, padding_idx=0, **kwargs):\n",
    "        \"\"\" default padding_idx=0.\n",
    "        \n",
    "        Call Args:\n",
    "            inputs: [B, T]\n",
    "        \n",
    "        description:\n",
    "            input_dim: V (vocabulary size)\n",
    "            output_dim: D \n",
    "        \"\"\"\n",
    "        super(Embedding, self).__init__(**kwargs)\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.padding_idx = padding_idx\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.embeddings = self.add_weight(\n",
    "          shape=(self.input_dim, self.output_dim),\n",
    "          initializer='random_normal',\n",
    "          dtype='float32')\n",
    "\n",
    "    def call(self, inputs): \n",
    "        def compute_mask():\n",
    "            return tf.not_equal(inputs, self.padding_idx)\n",
    "        \n",
    "        out = tf.nn.embedding_lookup(self.embeddings, inputs)\n",
    "        masking = compute_mask() # [B, T], bool\n",
    "        masking = tf.cast(tf.tile(masking[:,:, tf.newaxis], [1,1,self.output_dim]), \n",
    "                          dtype=tf.float32) # [B, T, D]\n",
    "        return tf.multiply(out, masking)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = Embedding(V, D, padding_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### regenerate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      "[[101  25  11   0   0]\n",
      " [757 978   0   0   0]]\n",
      "x_len:\n",
      "[3 2]\n",
      "mask:\n",
      "[[ True  True  True False False]\n",
      " [ True  True False False False]]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randint(0, 1000, size=(B, T), dtype=int)\n",
    "# x_len = np.random.randint(0, T + 1, size=(B, ), dtype=int) # This will cause Error!!\n",
    "x_len = np.random.randint(1, T + 1, size=(B, ), dtype=int)\n",
    "for i in range(len(x)):\n",
    "    x[i][x_len[i]:] = 0\n",
    "mask = x!=0\n",
    "msg = \"x:\\n{}\\nx_len:\\n{}\\nmask:\\n{}\"\n",
    "print(msg.format(x, x_len, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to tensor\n",
    "inp = tf.convert_to_tensor(x, dtype=tf.int32)\n",
    "inp_len  = tf.convert_to_tensor(x_len, dtype=tf.int32)\n",
    "mask = tf.convert_to_tensor(mask, dtype=tf.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=904, shape=(2, 5), dtype=int32, numpy=\n",
       " array([[101,  25,  11,   0,   0],\n",
       "        [757, 978,   0,   0,   0]], dtype=int32)>,\n",
       " <tf.Tensor: id=906, shape=(2, 5), dtype=bool, numpy=\n",
       " array([[ True,  True,  True, False, False],\n",
       "        [ True,  True, False, False, False]])>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_mask = np.array([[True, False, False, False, False],\n",
    "#         [ True,  True,  True, False, False]])\n",
    "# test_mask = tf.convert_to_tensor(test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=930, shape=(2, 5, 3), dtype=float32, numpy=\n",
       "array([[[ 0.03622475, -0.05047853,  0.02699393],\n",
       "        [-0.01007628, -0.01224462,  0.04993922],\n",
       "        [ 0.0482391 , -0.04658696, -0.05432926],\n",
       "        [-0.        ,  0.        ,  0.        ],\n",
       "        [-0.        ,  0.        ,  0.        ]],\n",
       "\n",
       "       [[-0.07953385,  0.04829338, -0.09294441],\n",
       "        [-0.02257329,  0.03778542, -0.0711035 ],\n",
       "        [-0.        ,  0.        ,  0.        ],\n",
       "        [-0.        ,  0.        ,  0.        ],\n",
       "        [-0.        ,  0.        ,  0.        ]]], dtype=float32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = L.LSTM(units=H, return_sequences=True, return_state=True)\n",
    "blstm = L.Bidirectional(layer=lstm, merge_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=1112, shape=(2, 5, 2), dtype=float32, numpy=\n",
       " array([[[ 0.00167775,  0.00632184],\n",
       "         [ 0.00311793,  0.00512636],\n",
       "         [ 0.00476312,  0.00738899],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ]],\n",
       " \n",
       "        [[ 0.00939463, -0.01418047],\n",
       "         [ 0.00632864, -0.01470776],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ]]], dtype=float32)>,\n",
       " <tf.Tensor: id=1116, shape=(2, 2), dtype=float32, numpy=\n",
       " array([[ 0.00476312,  0.00738899],\n",
       "        [ 0.00632864, -0.01470776]], dtype=float32)>,\n",
       " <tf.Tensor: id=1120, shape=(2, 2), dtype=float32, numpy=\n",
       " array([[ 0.00965497,  0.01484598],\n",
       "        [ 0.01252178, -0.0303885 ]], dtype=float32)>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm(embed(inp), mask=mask) #  [h, ht, ct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=1356, shape=(2, 5, 2), dtype=float32, numpy=\n",
       " array([[[ 0.00474327,  0.00231616],\n",
       "         [ 0.00752271,  0.00516678],\n",
       "         [ 0.00160015,  0.00578936],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ]],\n",
       " \n",
       "        [[-0.01166129,  0.00491333],\n",
       "         [-0.01529764,  0.00018354],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ]]], dtype=float32)>,\n",
       " <tf.Tensor: id=1497, shape=(2, 5, 2), dtype=float32, numpy=\n",
       " array([[[-0.00333201, -0.00958159],\n",
       "         [-0.00097156, -0.00666697],\n",
       "         [-0.00971548,  0.00756083],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ]],\n",
       " \n",
       "        [[ 0.00411886,  0.01158959],\n",
       "         [-0.00268966,  0.01074356],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ]]], dtype=float32)>,\n",
       " <tf.Tensor: id=1360, shape=(2, 2), dtype=float32, numpy=\n",
       " array([[ 0.00160015,  0.00578936],\n",
       "        [-0.01529764,  0.00018354]], dtype=float32)>,\n",
       " <tf.Tensor: id=1364, shape=(2, 2), dtype=float32, numpy=\n",
       " array([[ 0.00319729,  0.0115598 ],\n",
       "        [-0.03100352,  0.00035776]], dtype=float32)>,\n",
       " <tf.Tensor: id=1490, shape=(2, 2), dtype=float32, numpy=\n",
       " array([[-0.00333201, -0.00958159],\n",
       "        [ 0.00411886,  0.01158959]], dtype=float32)>,\n",
       " <tf.Tensor: id=1494, shape=(2, 2), dtype=float32, numpy=\n",
       " array([[-0.00665976, -0.01863865],\n",
       "        [ 0.00814336,  0.02448629]], dtype=float32)>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blstm(embed(inp), mask=mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ts20",
   "language": "python",
   "name": "ts20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
