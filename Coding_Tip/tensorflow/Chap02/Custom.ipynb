{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Traing with tf.distribution\n",
    "\n",
    "This tutorial demonstrates how to use `tf.distribute.Strategy` with custom training loops. We will train a simple CNN model on the fashion MNIST dataset. The fashion MNIST dataset contains 60000 train images of size 28 x 28 and 10000 test images of size 28 x 28.\n",
    "\n",
    "We are using custom training loops to train our model because they give us flexibility and a greater control on training. Moreover, it is easier to debug the model and the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_dir = './distribute_s2' # section 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "[VirtualDeviceConfiguration(memory_limit=5120)]\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "# GPU 메모리 제한하기\n",
    "MEMORY_LIMIT_CONFIG = [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)]\n",
    "print(MEMORY_LIMIT_CONFIG)\n",
    "tf.config.experimental.set_virtual_device_configuration(gpus[0], MEMORY_LIMIT_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# Adding a dimension to the array -> new shape == (28, 28, 1)\n",
    "# We are doing this because the first layer in our model is a convolutional\n",
    "# layer and it requires a 4D input (batch_size, height, width, channels).\n",
    "# batch_size dimension will be added later on.\n",
    "train_images = train_images[..., None]\n",
    "test_images = test_images[..., None]\n",
    "\n",
    "# Getting the images in [0, 1] range.\n",
    "train_images = train_images / np.float32(255)\n",
    "test_images = test_images / np.float32(255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 1), (10000, 28, 28, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape, test_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a strategy to distribute the variables and the graph  \n",
    "How does tf.distribute.MirroredStrategy strategy work?\n",
    "\n",
    "* All the variables and the model graph is replicated on the replicas.\n",
    "* Input is evenly distributed across the replicas.\n",
    "* Each replica calculates the loss and gradients for the input it received.\n",
    "* The gradients are synced across all the replicas by summing them.\n",
    "* After the sync, the same update is made to the copies of the variables on each replica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 1\n"
     ]
    }
   ],
   "source": [
    "# If the list of devices is not specified in the\n",
    "# `tf.distribute.MirroredStrategy` constructor, it will be auto-detected.\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "print ('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup input pipeline  \n",
    "Export the graph and the variables to the platform-agnostic SavedModel format. After your model is saved, you can load it with or without the scope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(train_images)\n",
    "BATCH_SIZE_PER_REPLICA = 64\n",
    "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the datasets and distribute them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(BUFFER_SIZE).batch(GLOBAL_BATCH_SIZE) \n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(GLOBAL_BATCH_SIZE) \n",
    "# and distribute them\n",
    "train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)\n",
    "test_dist_dataset = strategy.experimental_distribute_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_batch, label_batch = next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 28, 28, 1]), TensorShape([64]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_batch.shape, label_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dist, label_dist = next(iter(train_dist_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 28, 28, 1]), TensorShape([64]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_dist.shape, label_dist.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(),\n",
    "      tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(64, activation='relu'),\n",
    "      tf.keras.layers.Dense(10, activation='softmax')])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_example = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 10])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_example(img_batch).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a checkpoint directory to store the checkpoints.\n",
    "checkpoint_dir = os.path.join(root_dir, 'checkpoints')\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the loss function\n",
    "Normally, on a single machine with 1 GPU/CPU, loss is divided by the number of examples in the batch of input.\n",
    "\n",
    "So, how should the loss be calculated when using a tf.distribute.Strategy?\n",
    "\n",
    "* For an example, let's say you have 4 GPU's and a batch size of 64. One batch of input is distributed across the replicas (4 GPUs), each replica getting an input of size 16.\n",
    "\n",
    "* The model on each replica does a forward pass with its respective input and calculates the loss. Now, instead of dividing the loss by the number of examples in its respective input (BATCH_SIZE_PER_REPLICA = 16), the loss should be divided by the GLOBAL_BATCH_SIZE (64).\n",
    "\n",
    "Why do this?\n",
    "\n",
    "* This needs to be done because after the gradients are calculated on each replica, they are synced across the replicas by summing them.\n",
    "How to do this in TensorFlow?\n",
    "\n",
    "* If you're writing a custom training loop, as in this tutorial, you should sum the per example losses and divide the sum by the GLOBAL_BATCH_SIZE: scale_loss = tf.reduce_sum(loss) * (1. / GLOBAL_BATCH_SIZE) or you can use tf.nn.compute_average_loss which takes the per example loss, optional sample weights, and GLOBAL_BATCH_SIZE as arguments and returns the scaled loss.\n",
    "\n",
    "* If you are using regularization losses in your model then you need to scale the loss value by number of replicas. You can do this by using the tf.nn.scale_regularization_loss function.\n",
    "\n",
    "* Using tf.reduce_mean is not recommended. Doing so divides the loss by actual per replica batch size which may vary step to step.\n",
    "\n",
    "* This reduction and scaling is done automatically in keras model.compile and model.fit\n",
    "\n",
    "* If using tf.keras.losses classes (as in the example below), the loss reduction needs to be explicitly specified to be one of NONE or SUM. AUTO and SUM_OVER_BATCH_SIZE are disallowed when used with tf.distribute.Strategy. AUTO is disallowed because the user should explicitly think about what reduction they want to make sure it is correct in the distributed case. SUM_OVER_BATCH_SIZE is disallowed because currently it would only divide by per replica batch size, and leave the dividing by number of replicas to the user, which might be easy to miss. So instead we ask the user do the reduction themselves explicitly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    # Set reduction to `none` so we can do the reduction afterwards and divide by\n",
    "    # global batch size.\n",
    "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    # or loss_fn = tf.keras.losses.sparse_categorical_crossentropy\n",
    "    def compute_loss(labels, predictions):\n",
    "        per_example_loss = loss_object(labels, predictions)\n",
    "        return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64]), TensorShape([64, 10]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_batch.shape, model_example(img_batch).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# __call__(y_true, y_pred) was predifined in tf.keras.losses.SparseCategoricalCrossentropy \n",
    "loss_object(y_true=label_batch, y_pred=model_example(img_batch)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.61779296 0.8859636  0.5906766 ], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "cce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "# cce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='auto')\n",
    "# cce = tf.keras.losses.SparseCategoricalCrossentropy(reduction='none')\n",
    "print(cce(tf.convert_to_tensor([0, 1, 2]), tf.convert_to_tensor([[.9, .05, .05], [.5, .89, .6], [.05, .01, .94]])))\n",
    "# from_logits=True, redution='auto' will lead to 0.6981444"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=320, shape=(), dtype=float32, numpy=0.6981444>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GLOBAL_BATCH_SIZE = 3 example\n",
    "tf.nn.compute_average_loss(per_example_loss=cce(tf.convert_to_tensor([0, 1, 2]), \n",
    "                                                tf.convert_to_tensor([[.9, .05, .05], [.5, .89, .6], [.05, .01, .94]]))\n",
    "                           ,global_batch_size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the metrics to track loss and accuracy\n",
    "\n",
    "These metrics track the test loss and training and test accuracy. You can use .result() to get the accumulated statistics at any time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "    test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model and optimizer must be created under `strategy.scope`.\n",
    "with strategy.scope():\n",
    "    model = create_model()\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `experimental_run_v2` inside a tf.function to get the best performance.\n",
      "(64, 28, 28, 1) (64,)\n",
      "tf.Tensor(2.3160014, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# example of distribute\n",
    "data_dist = (img_dist, label_dist)\n",
    "def f_dist(inputs):\n",
    "    images, labels = inputs\n",
    "    print(images.shape, labels.shape)\n",
    "    predictions = model(images)\n",
    "    loss = compute_loss(labels, predictions)\n",
    "    return loss \n",
    "\n",
    "with strategy.scope():\n",
    "    per_replica_losses = strategy.experimental_run_v2(f_dist, args=(data_dist,))\n",
    "    print(per_replica_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that different function is used when computing loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    def train_step(inputs):\n",
    "        images, labels = inputs\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = model(images, training=True)\n",
    "            loss = compute_loss(labels, predictions)\n",
    "\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        \n",
    "        train_accuracy.update_state(labels, predictions)\n",
    "        return loss \n",
    "\n",
    "    def test_step(inputs):\n",
    "        images, labels = inputs\n",
    "\n",
    "        predictions = model(images, training=False)\n",
    "        t_loss = loss_object(labels, predictions)\n",
    "\n",
    "        test_loss.update_state(t_loss)\n",
    "        test_accuracy.update_state(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Epoch 1, Loss: 0.513, Accuracy: 81.443, Test Loss: 81.443, Test Accuracy: 81.443\n",
      "Epoch 2, Loss: 0.337, Accuracy: 87.820, Test Loss: 87.820, Test Accuracy: 87.820\n",
      "Epoch 3, Loss: 0.296, Accuracy: 89.225, Test Loss: 89.225, Test Accuracy: 89.225\n",
      "Epoch 4, Loss: 0.266, Accuracy: 90.335, Test Loss: 90.335, Test Accuracy: 90.335\n",
      "Epoch 5, Loss: 0.243, Accuracy: 91.162, Test Loss: 91.162, Test Accuracy: 91.162\n",
      "Epoch 6, Loss: 0.225, Accuracy: 91.805, Test Loss: 91.805, Test Accuracy: 91.805\n",
      "Epoch 7, Loss: 0.205, Accuracy: 92.422, Test Loss: 92.422, Test Accuracy: 92.422\n",
      "Epoch 8, Loss: 0.192, Accuracy: 92.860, Test Loss: 92.860, Test Accuracy: 92.860\n",
      "Epoch 9, Loss: 0.177, Accuracy: 93.563, Test Loss: 93.563, Test Accuracy: 93.563\n",
      "Epoch 10, Loss: 0.165, Accuracy: 93.903, Test Loss: 93.903, Test Accuracy: 93.903\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    # `experimental_run_v2` replicates the provided computation and runs it\n",
    "    # with the distributed input.\n",
    "    @tf.function\n",
    "    def distributed_train_step(dataset_inputs):\n",
    "        per_replica_losses = strategy.experimental_run_v2(train_step, args=(dataset_inputs,))\n",
    "        return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n",
    "\n",
    "    @tf.function\n",
    "    def distributed_test_step(dataset_inputs):\n",
    "        return strategy.experimental_run_v2(test_step, args=(dataset_inputs,))\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        # TRAIN LOOP\n",
    "        total_loss = 0.0\n",
    "        num_batches = 0\n",
    "        for x in train_dist_dataset:\n",
    "            total_loss += distributed_train_step(x)\n",
    "            num_batches += 1\n",
    "        train_loss = total_loss / num_batches\n",
    "\n",
    "        # TEST LOOP\n",
    "        for x in test_dist_dataset:\n",
    "            distributed_test_step(x)\n",
    "\n",
    "        if epoch % 2 == 0:\n",
    "            checkpoint.save(checkpoint_prefix)\n",
    "\n",
    "        template = (\"Epoch {0:}, Loss: {1:.3f}, Accuracy: {2:.3f}, Test Loss: {2:.3f}, Test Accuracy: {2:.3f}\")\n",
    "        print (template.format(epoch+1, train_loss,\n",
    "                               train_accuracy.result()*100, test_loss.result(),\n",
    "                               test_accuracy.result()*100))\n",
    "        \n",
    "        # initialize tf.keras.metrics.* object\n",
    "        test_loss.reset_states()\n",
    "        train_accuracy.reset_states()\n",
    "        test_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to note in the example above:\n",
    "\n",
    "* We are iterating over the `train_dist_dataset` and `test_dist_dataset` using a for x in ... construct.\n",
    "* The scaled loss is the return value of the `distributed_train_step`. This value is aggregated across replicas using the `tf.distribute.Strategy.reduce` call and then across batches by summing the return value of the `tf.distribute.Strategy.reduce` calls.\n",
    "* `tf.keras.Metrics` should be updated inside train_step and test_step that gets executed by `tf.distribute.Strategy.experimental_run_v2`.\n",
    "* `tf.distribute.Strategy.experimental_run_v2` returns results from each local replica in the strategy, and there are multiple ways to consume this result. You can do `tf.distribute.Strategy.reduce` to get an aggregated value. You can also do `tf.distribute.Strategy.experimental_local_results` to get the list of values contained in the result, one per local replica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore the latest checkpoint and test\n",
    "\n",
    "A model checkpointed with a tf.distribute.Strategy can be restored with or without a strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='eval_accuracy')\n",
    "new_model = create_model()\n",
    "new_optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def eval_step(images, labels):\n",
    "    predictions = new_model(images, training=False)\n",
    "    eval_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./distribute_s2/checkpoints\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fa9488e2d10>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = tf.train.Checkpoint(optimizer=new_optimizer, model=new_model)\n",
    "print(checkpoint_dir)\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after restoring the saved model without strategy: 90.440\n"
     ]
    }
   ],
   "source": [
    "for images, labels in test_dataset:\n",
    "    eval_step(images, labels)\n",
    "\n",
    "print ('Accuracy after restoring the saved model without strategy: {0:.3f}'.format(\n",
    "    eval_accuracy.result()*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
